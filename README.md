# Attention 
Attention mechanism in neural networks aims to mimic human attention. It is usually defined using a Query, Key and Values. In a real life situation one could relate to queries keys and values with the following scenario. You are searching for a restaurant to have dinner, the attention mechanism would help you to focus on certain aspects of the restaurant (the values) based on your personal preferences (queries) and the information available (keys).

   - **Queries** could be the information you are looking for : italian, cheap, cosy.
   - **Keys** could be the information about each restaurant helping you to make a decision.
   - **Values** being the actual restaurant, the name for example.
  
The goal of attention mechanism is to compute a similarity between your query and the keys, in order to weight each values (restaurants), allowing to prioritize the restaurant matching your request as much as possible.

# Visualizing Attention weights
In these notebooks, we demonstrate two ways to visualize attention weights for different types of classification tasks:

   - Image Classification using a CNN
   - Text Classification using a RNN






